"""thesis.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/122nUb1h1BccuGx8FCUowk_XrZ18Hv8Nz

First, we need to allow access to google drive to get the processed dataset
"""

import pathlib
import matplotlib.pyplot as plt
import pandas as pd
import seaborn as sns
import tensorflow as tf
from tensorflow import keras
from tensorflow.nn import relu, leaky_relu
from tensorflow.keras import layers
from math import sqrt
from keras import regularizers
import numpy as np

"""Importing dataset and select columns needed"""

dataset_path = './data.csv'
selected_columns = [
    'tmp_10_t-1',
    'tmp_11_t-1',
    'tmp_12_t-1',
    'tmp_1',
    'tmp_2',
    'pre_10_t-1',
    'pre_11_t-1',
    'pre_12_t-1',
    'pre_1',
    'pre_2',
    'yield_t-1',
    'yield'
]

dataset = pd.read_csv(dataset_path, sep=",", usecols=selected_columns)
dataset.head()

"""Load the dataset statistics and transpose it for use during normalization"""

stats = dataset.describe(include='all')
stats = stats.transpose()
stats

min = dataset.min()
max = dataset.max()

# MinMax Normalization Function


def minMaxNorm(data):
    return (data - min) / (max - min)


def minMaxDenorm(normedData):
    return ((normedData) * (max - min)) + min


"""Normalize the dataset. Min-max normalization is chosen because it preserves minimum and maximum range"""

dataset = minMaxNorm(dataset)
dataset.describe()

dataset.corr(method='pearson')

"""Split into training and test data then build persistence model"""

labels = dataset.pop('yield')

train = dataset.iloc[:35]
test = dataset.iloc[-12:]
train_labels = labels.iloc[:35]
test_labels = labels.iloc[-12:]

persistence = test.copy()
persistence = pd.DataFrame(persistence.pop('yield_t-1'))

persistence_train = train.copy()
persistence_train = pd.DataFrame(persistence_train.pop('yield_t-1'))

"""Retrieve yield for target/label"""


def save_history(history, name):
    hist = pd.DataFrame(history.history)
    hist['epoch'] = history.epoch

    plt.figure()
    plt.xlabel('Epoch')
    plt.ylabel('Mean Square Error [$qu/ha^2$]')
    plt.plot(hist['epoch'], hist['mean_squared_error'], label='Train Error')
    plt.plot(hist['epoch'], hist['val_mean_squared_error'], label='Val Error')
    plt.legend()
    plt.savefig('./trained_models/' + name + '.png')
    plt.close()


def build_model(nodes, activation, optimizer):
    model = keras.Sequential()

    for index, node in enumerate(nodes):
        if (activation == 'relu'):
            activation = relu
        elif (activation == 'leaky_relu'):
            activation = leaky_relu

        if (index == 0):
            model.add(layers.Dense(node, activation=activation, input_shape=[len(train.keys())]))
        else:
            model.add(layers.Dense(node, activation=activation))

    model.add(layers.Dense(1))

    if (optimizer == 'adam'):
        # Uncomment to use Adam as optimizer
        optimizer = tf.keras.optimizers.Adam(lr=0.01)
    else:
        # Uncomment to use SGD as optimizer
        optimizer = tf.keras.optimizers.SGD(lr=0.01, momentum=0.1)

    model.compile(loss='mean_squared_error', optimizer=optimizer, metrics=['mean_squared_error'])
    return model


def save_model(model, name):
    model.save('./trained_models/' + name + '.h5')


result = pd.read_csv('./result.csv')
activations = ['relu', 'leaky_relu']
optimizers = ['adam', 'sgd']
identifier = 2
nodes = 12
attempts = 10
counter = 1

iterations = len(activations) * len(optimizers) * nodes * attempts

for optimizer in optimizers:
    for activation in activations:
        for node in range(1, nodes):
            for i in range(0, attempts):
                model = build_model([node], activation, optimizer)

                """Fit model into training data then validate"""

                history = model.fit(
                    x=train,
                    y=train_labels,
                    epochs=1000,
                    validation_data=(test, test_labels),
                    verbose=0,  # Verbose had to be set to 0 due to google chrome crashing
                )

                hist = pd.DataFrame(history.history)
                hist['epoch'] = history.epoch
                hist.tail()

                """Calculate and plot error"""

                training_rmse = sqrt(hist['loss'].iloc[-1])
                validation_rmse = sqrt(hist['val_loss'].iloc[-1])

                new_row = {
                    'id': identifier,
                    'optimizer': optimizer,
                    'learning_rate': 0.01,
                    'activation': activation,
                    'epoch': 1000,
                    'configuration': ('11-' + str(node) + '-1'),
                    'train': training_rmse,
                    'val': validation_rmse,
                    'data': 'all'
                }

                print(new_row)

                should_save = (result.loc[(identifier), 'val'] > validation_rmse) if (
                    len(result.index) >= (identifier + 1)) else True
                new_model = (len(result.index) < (identifier + 1))

                if (should_save):
                    save_history(history, str(identifier))
                    save_model(model, str(identifier))

                    if (new_model):
                        result = result.append(
                            pd.DataFrame(new_row, index=[identifier]))
                    else:
                        result.update(pd.DataFrame(
                            new_row, index=[identifier]))

                    result.to_csv('./result.csv', header=True, index=False)
                    print('Replace Model: ', identifier)

            identifier = (identifier + 1)

for optimizer in optimizers:
    for activation in activations:
        for first_layer in range(1, nodes):
            for second_layer in range(1, nodes):
                for i in range(0, attempts):
                    configuration = [first_layer, second_layer]
                    model = build_model(configuration, activation, optimizer)

                    """Fit model into training data then validate"""

                    history = model.fit(
                        x=train,
                        y=train_labels,
                        epochs=1000,
                        validation_data=(test, test_labels),
                        verbose=0,  # Verbose had to be set to 0 due to google chrome crashing
                    )

                    hist = pd.DataFrame(history.history)
                    hist['epoch'] = history.epoch
                    hist.tail()

                    """Calculate and plot error"""

                    training_rmse = sqrt(hist['loss'].iloc[-1])
                    validation_rmse = sqrt(hist['val_loss'].iloc[-1])

                    new_row = {
                        'id': identifier, 
                        'optimizer': optimizer, 
                        'learning_rate': 0.01, 
                        'activation': activation, 
                        'epoch': 1000, 
                        'configuration': ('11-' + str(configuration) + '-1'), 
                        'train': training_rmse, 
                        'val': validation_rmse, 
                        'data': 'all'
                    }

                    print(new_row)

                    should_save = (result.loc[(identifier), 'val'] > validation_rmse) if (
                        len(result.index) >= (identifier + 1)) else True
                    new_model = (len(result.index) < (identifier + 1))

                    if (should_save):
                        save_history(history, str(identifier))
                        save_model(model, str(identifier))

                        if (new_model):
                            result = result.append(
                                pd.DataFrame(new_row, index=[identifier]))
                        else:
                            result.update(pd.DataFrame(
                                new_row, index=[identifier]))

                        result.to_csv('./result.csv', header=True, index=False)
                        print('Replace Model: ', identifier)

                identifier = (identifier + 1)
